{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interactive Training (CIFAR-10)\n",
        "\n",
        "This notebook lets you configure, train, and visualize the CIFAR-10 model end-to-end.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objectives\n",
        "- Achieve ≥ 85% test accuracy on CIFAR-10\n",
        "- Keep parameters < 200k\n",
        "- Ensure receptive field > 44\n",
        "- Use C1C2C3C4 architecture without MaxPooling\n",
        "- Include Depthwise Separable Conv (C2) and Dilated Convs (C3/C4)\n",
        "- Use GAP, Albumentations (HF, ShiftScaleRotate, CoarseDropout)\n",
        "\n",
        "### Key Features\n",
        "- C1C2C3C4 network with dilations (d=2,4,8) and DW separable conv in C2\n",
        "- Global Average Pooling + Linear head\n",
        "- Albumentations pipeline with dataset mean/std\n",
        "- OneCycleLR schedule (base lr=0.003, max_lr=0.2) for faster convergence\n",
        "- Detailed metrics: train/test accuracy, train/test loss, LR curve\n",
        "- Visualizations: training curves, per-class accuracy, misclassified images\n",
        "- Interactive cells to override config, train, and analyze results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !git clone https://github.com/SachinDangayach/AU_7_NN_CIFAR.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive Training Notebook\n",
        "# Use: Run cells top-to-bottom. Adjust config overrides in the next cell.\n",
        "import os, sys\n",
        "\n",
        "# Add the cloned repository directory to the Python path\n",
        "# sys.path.append('/content/AU_7_NN_CIFAR')\n",
        "# sys.path.append('/kaggle/working/AU_7_NN_CIFAR')\n",
        "\n",
        "from config import get_config, ProjectConfig\n",
        "from src.data.data_manager import create_data_manager\n",
        "from src.models.model import create_model\n",
        "from src.training.trainer import create_trainer\n",
        "from src.visualization.visualizer import create_visualizer\n",
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "config = get_config()\n",
        "config.training.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Batch size: {config.data.batch_size}\")\n",
        "print(f\"Scheduler: {config.training.scheduler_type}, base LR={config.training.learning_rate}, max_lr={getattr(config.training,'max_lr', None)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: override some config values here\n",
        "# Example: faster experimentation\n",
        "config.training.max_epochs = 30\n",
        "config.training.scheduler_type = 'OneCycleLR'\n",
        "config.training.learning_rate = 0.003\n",
        "config.training.max_lr = 0.2\n",
        "config.training.post_target_extra_epochs = 3\n",
        "config.training.target_test_accuracy = 85.0\n",
        "\n",
        "# Print quick summary\n",
        "from config import print_config\n",
        "print_config(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick verification: run a dummy forward pass\n",
        "if 'model' not in locals():\n",
        "    model = create_model(config.model).to(device)\n",
        "\n",
        "x = torch.randn(2, 3, 32, 32).to(device)\n",
        "out = model(x)\n",
        "print(\"Input:\", tuple(x.shape), \"Output:\", tuple(out.shape))\n",
        "assert out.shape[-1] == config.model.num_classes, \"Output classes mismatch\"\n",
        "print(\"✅ Forward pass OK\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data\n",
        "data_manager = create_data_manager(config.data)\n",
        "# Optionally compute dataset stats (commented for speed)\n",
        "# mean, std = data_manager.calculate_dataset_statistics()\n",
        "train_t, test_t = data_manager.create_transforms()\n",
        "train_ds, test_ds = data_manager.load_datasets(train_t, test_t)\n",
        "train_loader, test_loader = data_manager.create_data_loaders(train_ds, test_ds)\n",
        "\n",
        "print(len(train_loader), len(test_loader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = create_model(config.model).to(device)\n",
        "\n",
        "# Count parameters\n",
        "from src.models.model import count_model_parameters\n",
        "total_params = count_model_parameters(model)\n",
        "\n",
        "print(f\"Model created successfully!\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Parameter requirement (< {config.model.max_parameters:,}): {'✓' if total_params < config.model.max_parameters else '✗'}\")\n",
        "\n",
        "# Display model summary\n",
        "viz = create_visualizer(config.visualization)\n",
        "viz.display_model_summary(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print full model architecture summary\n",
        "from src.visualization.visualizer import create_visualizer\n",
        "if 'model' not in locals():\n",
        "    model = create_model(config.model).to(device)\n",
        "visualizer = create_visualizer(config.visualization)\n",
        "visualizer.display_model_summary(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Curves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model and trainer\n",
        "model = create_model(config.model).to(device)\n",
        "trainer = create_trainer(model, config.training, device)\n",
        "\n",
        "metrics = trainer.train(\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    max_epochs=config.training.max_epochs,\n",
        "    target_test_acc=config.training.target_test_accuracy,\n",
        "    post_target_extra_epochs=config.training.post_target_extra_epochs,\n",
        ")\n",
        "\n",
        "best = metrics.get_best_metrics()\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f\"Best test accuracy: {best.get('best_test_accuracy', float('nan')):.2f}%\")\n",
        "print(f\"Best epoch: {best.get('best_epoch', -1)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize curves\n",
        "visualizer = create_visualizer(config.visualization)\n",
        "visualizer.plot_training_curves(\n",
        "    metrics.train_losses,\n",
        "    metrics.train_accuracies,\n",
        "    metrics.learning_rates,\n",
        "    None,  # or provide a save path like 'training_curves.png'\n",
        "    metrics.test_accuracies,\n",
        "    metrics.test_losses,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis: Per-Class Accuracy and Misclassifications\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: visualize per-class accuracy and misclassified images\n",
        "from src.data.data_manager import CIFAR10DataManager\n",
        "class_names = train_ds.classes\n",
        "\n",
        "# Per-class accuracy\n",
        "_ = visualizer.plot_per_class_accuracy(model, test_loader, class_names, device)\n",
        "\n",
        "# Misclassified images\n",
        "visualizer.analyze_misclassified_images(model, test_loader, class_names, device=device, num_images=16)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
