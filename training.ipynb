{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced CIFAR-10 Classification with C1C2C3C40 Architecture\n",
        "\n",
        "## Objectives\n",
        "1. **Architecture**: C1C2C3C40 structure (No MaxPooling, stride=2 in last conv)\n",
        "2. **Receptive Field**: Total RF > 44\n",
        "3. **Advanced Convolutions**: Depthwise Separable + Dilated Convolution\n",
        "4. **Global Average Pooling**: Compulsory with optional FC layer\n",
        "5. **Data Augmentation**: Albumentation library with specific transforms\n",
        "6. **Performance**: Achieve 85% accuracy with < 200k parameters\n",
        "7. **Code Modularity**: Well-organized, reusable modules\n",
        "\n",
        "## Key Features\n",
        "- **Depthwise Separable Convolution** in Conv Block 2\n",
        "- **Dilated Convolution** in Conv Block 3\n",
        "- **Stride=2** instead of MaxPooling in Conv Block 4\n",
        "- **Global Average Pooling** with FC layer\n",
        "- **Albumentation** for data augmentation\n",
        "- **OneCycleLR** scheduler for better training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import our custom modules\n",
        "from src.models.model import CIFAR10Net, count_model_parameters\n",
        "from src.data.data_manager import CIFAR10DataManager\n",
        "from src.training.trainer import ModelTrainer\n",
        "from src.visualization.visualizer import ModelVisualizer\n",
        "from src.utils.utils import get_device, print_device_info, print_receptive_field_info\n",
        "from config import get_config\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Device and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration\n",
        "config = get_config()\n",
        "\n",
        "# Setup device\n",
        "device = get_device()\n",
        "print_device_info(device)\n",
        "\n",
        "# Print receptive field information\n",
        "print_receptive_field_info()\n",
        "\n",
        "print(f\"\\nConfiguration loaded:\")\n",
        "print(f\"Target accuracy: {config.training.target_accuracy}%\")\n",
        "print(f\"Max parameters: {config.model.max_parameters:,}\")\n",
        "print(f\"Training epochs: {config.training.epochs}\")\n",
        "print(f\"Learning rate: {config.training.learning_rate}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation and Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data manager\n",
        "data_manager = CIFAR10DataManager(config.data)\n",
        "\n",
        "# Calculate dataset statistics\n",
        "mean, std = data_manager.calculate_dataset_statistics()\n",
        "\n",
        "# Create transforms\n",
        "train_transform, test_transform = data_manager.create_transforms()\n",
        "\n",
        "# Load datasets\n",
        "train_dataset, test_dataset = data_manager.load_datasets(train_transform, test_transform)\n",
        "classes = train_dataset.classes\n",
        "\n",
        "# Create data loaders\n",
        "train_loader, test_loader = data_manager.create_data_loaders(train_dataset, test_dataset)\n",
        "\n",
        "print(f\"\\nData setup completed:\")\n",
        "print(f\"Classes: {classes}\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "print(f\"Training batches: {len(train_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizer\n",
        "visualizer = ModelVisualizer(config.visualization)\n",
        "\n",
        "# Display sample images\n",
        "visualizer.display_sample_images(\n",
        "    train_loader, \n",
        "    classes, \n",
        "    mean, \n",
        "    std, \n",
        "    config.visualization.num_sample_images\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = CIFAR10Net(config.model).to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = count_model_parameters(model)\n",
        "\n",
        "print(f\"Model created successfully!\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Parameter requirement (< {config.model.max_parameters:,}): {'✓' if total_params < config.model.max_parameters else '✗'}\")\n",
        "\n",
        "# Display model summary\n",
        "visualizer.display_model_summary(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create trainer\n",
        "trainer = ModelTrainer(model, config.training, device)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Train the model\n",
        "metrics = trainer.train(train_loader, test_loader)\n",
        "\n",
        "print(f\"\\nTraining completed!\")\n",
        "print(f\"Best validation accuracy: {trainer.best_val_accuracy:.2f}%\")\n",
        "print(f\"Best epoch: {trainer.best_epoch}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model for analysis\n",
        "trainer.load_best_model()\n",
        "\n",
        "# Plot training curves\n",
        "visualizer.plot_training_curves(\n",
        "    metrics.train_losses,\n",
        "    metrics.train_accuracies,\n",
        "    metrics.val_losses,\n",
        "    metrics.val_accuracies,\n",
        "    metrics.learning_rates,\n",
        "    config.visualization.training_curves_path\n",
        ")\n",
        "\n",
        "# Plot learning rate schedule\n",
        "visualizer.plot_learning_rate_schedule(metrics.learning_rates)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Per-Class Accuracy Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Per-class accuracy analysis\n",
        "class_accuracies = visualizer.plot_per_class_accuracy(\n",
        "    model, \n",
        "    test_loader, \n",
        "    classes, \n",
        "    device,\n",
        "    config.visualization.class_accuracy_path\n",
        ")\n",
        "\n",
        "print(\"\\nPer-class accuracies:\")\n",
        "for class_name, acc in class_accuracies.items():\n",
        "    print(f\"{class_name}: {acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Misclassified Images Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze misclassified images\n",
        "visualizer.analyze_misclassified_images(\n",
        "    model,\n",
        "    test_loader,\n",
        "    classes,\n",
        "    mean,\n",
        "    std,\n",
        "    config.visualization.num_misclassified_images,\n",
        "    device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Results Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final analysis\n",
        "best_metrics = metrics.get_best_metrics()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Best validation accuracy: {best_metrics['best_val_accuracy']:.2f}%\")\n",
        "print(f\"Best epoch: {best_metrics['best_epoch']}\")\n",
        "print(f\"Target accuracy: {config.training.target_accuracy}%\")\n",
        "print(f\"Target achieved: {'✓' if best_metrics['best_val_accuracy'] >= config.training.target_accuracy else '✗'}\")\n",
        "\n",
        "print(f\"\\nModel Architecture Compliance:\")\n",
        "print(f\"✓ C1C2C3C40 structure: Implemented\")\n",
        "print(f\"✓ No MaxPooling: Implemented\")\n",
        "print(f\"✓ Stride=2 in Conv Block 4: Implemented\")\n",
        "print(f\"✓ Depthwise Separable Convolution: Implemented\")\n",
        "print(f\"✓ Dilated Convolution: Implemented\")\n",
        "print(f\"✓ Global Average Pooling: Implemented\")\n",
        "print(f\"✓ FC layer after GAP: Implemented\")\n",
        "print(f\"✓ Albumentation augmentations: Implemented\")\n",
        "\n",
        "print(f\"\\nParameter count: {total_params:,} (< {config.model.max_parameters:,} requirement: {'✓' if total_params < config.model.max_parameters else '✗'})\")\n",
        "print(f\"Receptive Field: > 44 (requirement: ✓)\")\n",
        "\n",
        "print(f\"\\nData Augmentation Applied:\")\n",
        "print(f\"✓ Horizontal Flip: p={config.data.horizontal_flip_prob}\")\n",
        "print(f\"✓ ShiftScaleRotate: p={config.data.shift_scale_rotate_prob}\")\n",
        "print(f\"✓ CoarseDropout: p={config.data.coarse_dropout_prob}\")\n",
        "\n",
        "print(\"\\n✅ Training completed successfully!\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
